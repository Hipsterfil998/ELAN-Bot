{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1E7N5SiaA7qSTXWti7bQzDFZZKPWerW6T","authorship_tag":"ABX9TyN0zV8HInw642ygmS2CnOlE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NyxVbOa1zNZ","executionInfo":{"status":"ok","timestamp":1743667454442,"user_tz":-120,"elapsed":10935,"user":{"displayName":"Filippo Pellegrino","userId":"07327118465539317388"}},"outputId":"3fca2777-dbbd-41f5-c068-1d72207d5239"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}],"source":["!pip install PyPDF2"]},{"cell_type":"code","source":["import PyPDF2\n","import re\n","import pickle\n","\n","def extract_text_from_pdf(pdf_path):\n","    \"\"\"\n","    Extract text from a PDF file.\n","\n","    Args:\n","        pdf_path (str): Path to the PDF file.\n","\n","    Returns:\n","        str: Extracted text from the PDF.\n","    \"\"\"\n","    try:\n","        text = \"\"\n","        with open(pdf_path, 'rb') as file:\n","            pdf_reader = PyPDF2.PdfReader(file)\n","            num_pages = len(pdf_reader.pages)\n","\n","            for page_num in range(num_pages):\n","                page = pdf_reader.pages[page_num]\n","                text += page.extract_text()\n","\n","        return text\n","\n","    except Exception as e:\n","        return f\"Error: {str(e)}\"\n","\n","def process_text(text):\n","    \"\"\"\n","    Trova tutti gli elementi che corrispondono al pattern tipico di un indice:\n","    testo seguito da una serie di punti e un numero di pagina.\n","\n","    Args:\n","        testo (str): Il testo in cui cercare il pattern\n","\n","    Returns:\n","        list: Lista di tuple (titolo, numero_pagina)\n","    \"\"\"\n","    # Pattern regex: testo seguito da almeno 5 punti e poi un numero, escludendo titoli che iniziano con un numero e un punto\n","    pattern = r'(?<!\\d\\.\\s)(.+?)\\s*\\.{5,}\\s*(\\d+)'\n","\n","    # Trova tutte le corrispondenze\n","    matches = re.findall(pattern, text, re.MULTILINE)\n","\n","    # Pulisci i risultati (rimuovi spazi extra)\n","    results = [(title.strip(), int(page)) for title, page in matches if re.match(r'\\b\\w+(\\s+\\w+)+\\b', title)]\n","\n","    return results\n","\n","\n","def cut_text_before_phrase(text, phrase):\n","    \"\"\"\n","    Cuts all text before the specified phrase.\n","\n","    Args:\n","        text (str): The original text.\n","        phrase (str): The phrase to search for.\n","\n","    Returns:\n","        str: The text starting from the specified phrase.\n","    \"\"\"\n","    # Find the index of the phrase in the text\n","    index = text.find(phrase)\n","\n","    # If the phrase is found, return the text starting from that phrase\n","    if index != -1:\n","        return text[index:]\n","    else:\n","        # If the phrase is not found, return the original text\n","        return text\n","\n","\n","def dividi_testo_per_titoli(testo, lista_titoli):\n","    \"\"\"\n","    Divide il testo in chunk in base ai titoli forniti in una lista di tuple.\n","    Considera un titolo valido solo se è preceduto da un carattere newline.\n","\n","    Args:\n","        testo (str): Il testo completo da dividere\n","        lista_titoli (list): Lista di tuple (titolo, livello) dove titolo è il pattern da cercare\n","\n","    Returns:\n","        list: Lista di dizionari, ciascuno contenente il titolo, il livello e il contenuto del chunk\n","    \"\"\"\n","    chunks = []\n","\n","    # Estrai solo i titoli dalle tuple e crea un dizionario di mappatura titolo -> livello\n","    titoli_livelli = {titolo: livello for titolo, livello in lista_titoli}\n","\n","    # Ordina i titoli dal più lungo al più corto per evitare matching parziali\n","    titoli_ordinati = sorted(titoli_livelli.keys(), key=len, reverse=True)\n","\n","    # Assicurati che il testo inizi con un newline per catturare titoli all'inizio\n","    testo_con_newline = '\\n' + testo if not testo.startswith('\\n') else testo\n","\n","    # Trova tutte le posizioni dei titoli nel testo\n","    matches = []\n","    for titolo in titoli_ordinati:\n","        # Cerca il titolo ma solo se viene dopo un newline\n","        pattern = r'\\n' + re.escape(titolo)\n","        for match in re.finditer(pattern, testo_con_newline):\n","            # Memorizza il titolo e la posizione\n","            matches.append((match.start(), match.end(), titolo))\n","\n","    # Ordina i match per posizione\n","    matches.sort(key=lambda x: x[0])\n","\n","    # Se non ci sono match, restituisci una lista vuota\n","    if not matches:\n","        return chunks\n","\n","    # Processa ogni match per dividere il testo\n","    for i, (start, end, titolo_trovato) in enumerate(matches):\n","        # L'inizio effettivo del contenuto è dopo il newline + titolo\n","        inizio = start + 1  # +1 per saltare il newline iniziale\n","\n","        # Calcola la fine della sezione (inizio della sezione successiva o fine del testo)\n","        fine = matches[i+1][0] if i < len(matches) - 1 else len(testo_con_newline)\n","\n","        # Estrai il testo per questa sezione\n","        contenuto = testo_con_newline[inizio:fine].strip()\n","\n","        # Crea il chunk e aggiungilo alla lista\n","        chunk = {\n","            'title': titolo_trovato,\n","            'content': contenuto\n","        }\n","        chunks.append(chunk)\n","\n","    return chunks\n","\n","\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    pdf_path = \"/content/drive/MyDrive/ELAN_manual.pdf\"  # Replace with your PDF file path\n","    extracted_text = extract_text_from_pdf(pdf_path)\n","    titles = process_text(extracted_text)\n","    cleaned_text = cut_text_before_phrase(extracted_text, \"xxiChapter 1. ELAN documents\")\n","    chunks = dividi_testo_per_titoli(cleaned_text, titles)\n","    chunks_cleaned = [el for el in chunks if el['title'] != el['content']]\n","    with open('/content/drive/MyDrive/ELAN_chunks.pkl', 'wb') as file:\n","      pickle.dump(chunks_cleaned, file)\n","\n","\n","\n"],"metadata":{"id":"huUf3exm2dRS","executionInfo":{"status":"ok","timestamp":1743672180996,"user_tz":-120,"elapsed":16015,"user":{"displayName":"Filippo Pellegrino","userId":"07327118465539317388"}}},"execution_count":14,"outputs":[]}]}