{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1E7N5SiaA7qSTXWti7bQzDFZZKPWerW6T","authorship_tag":"ABX9TyOr4L0Q3Qmv8Kkhhq6961z+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NyxVbOa1zNZ","executionInfo":{"status":"ok","timestamp":1743667454442,"user_tz":-120,"elapsed":10935,"user":{"displayName":"Filippo Pellegrino","userId":"07327118465539317388"}},"outputId":"3fca2777-dbbd-41f5-c068-1d72207d5239"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}],"source":["!pip install PyPDF2"]},{"cell_type":"code","source":["import PyPDF2\n","import re\n","import pickle\n","\n","def extract_text_from_pdf(pdf_path):\n","    \"\"\"\n","    Extract text from a PDF file.\n","\n","    Args:\n","        pdf_path (str): Path to the PDF file.\n","\n","    Returns:\n","        str: Extracted text from the PDF.\n","    \"\"\"\n","    try:\n","        text = \"\"\n","        with open(pdf_path, 'rb') as file:\n","            pdf_reader = PyPDF2.PdfReader(file)\n","            num_pages = len(pdf_reader.pages)\n","\n","            for page_num in range(num_pages):\n","                page = pdf_reader.pages[page_num]\n","                text += page.extract_text()\n","\n","        return text\n","\n","    except Exception as e:\n","        return f\"Error: {str(e)}\"\n","\n","def process_text(text):\n","    \"\"\"\n","    Find all elements that match the typical pattern of an index:\n","    text followed by a series of dots and a page number.\n","\n","    Args:\n","        text (str): The text in which to search for the pattern\n","\n","    Returns:\n","        list: List of tuples (title, page_number)\n","    \"\"\"\n","    # Regex pattern: text followed by at least 5 dots and then a number, excluding titles that start with a number and a dot\n","    pattern = r'(?<!\\d\\.\\s)(.+?)\\s*\\.{5,}\\s*(\\d+)'\n","\n","    # Find all matches\n","    matches = re.findall(pattern, text, re.MULTILINE)\n","\n","    # Clean the results (remove extra spaces)\n","    results = [(title.strip(), int(page)) for title, page in matches if re.match(r'\\b\\w+(\\s+\\w+)+\\b', title)]\n","\n","    return results\n","\n","\n","def cut_text_before_phrase(text, phrase):\n","    \"\"\"\n","    Cuts all text before the specified phrase.\n","\n","    Args:\n","        text (str): The original text.\n","        phrase (str): The phrase to search for.\n","\n","    Returns:\n","        str: The text starting from the specified phrase.\n","    \"\"\"\n","    # Find the index of the phrase in the text\n","    index = text.find(phrase)\n","\n","    # If the phrase is found, return the text starting from that phrase\n","    if index != -1:\n","        return text[index:]\n","    else:\n","        # If the phrase is not found, return the original text\n","        return text\n","\n","\n","def divide_text_by_titles(text, title_list):\n","    \"\"\"\n","    Divides the text into chunks based on the titles provided in a list of tuples.\n","    Considers a title valid only if it is preceded by a newline character.\n","\n","    Args:\n","        text (str): The complete text to divide\n","        title_list (list): List of tuples (title, level) where title is the pattern to search for\n","\n","    Returns:\n","        list: List of dictionaries, each containing the title, level, and content of the chunk\n","    \"\"\"\n","    chunks = []\n","\n","    # Extract only the titles from the tuples and create a mapping dictionary title -> level\n","    titles_levels = {title: level for title, level in title_list}\n","\n","    # Sort titles from longest to shortest to avoid partial matching\n","    sorted_titles = sorted(titles_levels.keys(), key=len, reverse=True)\n","\n","    # Make sure the text starts with a newline to capture titles at the beginning\n","    text_with_newline = '\\n' + text if not text.startswith('\\n') else text\n","\n","    # Find all positions of titles in the text\n","    matches = []\n","    for title in sorted_titles:\n","        # Look for the title but only if it comes after a newline\n","        pattern = r'\\n' + re.escape(title)\n","        for match in re.finditer(pattern, text_with_newline):\n","            # Store the title and position\n","            matches.append((match.start(), match.end(), title))\n","\n","    # Sort matches by position\n","    matches.sort(key=lambda x: x[0])\n","\n","    # If there are no matches, return an empty list\n","    if not matches:\n","        return chunks\n","\n","    # Process each match to divide the text\n","    for i, (start, end, found_title) in enumerate(matches):\n","        # The effective start of the content is after the newline + title\n","        start_pos = start + 1  # +1 to skip the initial newline\n","\n","        # Calculate the end of the section (beginning of the next section or end of text)\n","        end_pos = matches[i+1][0] if i < len(matches) - 1 else len(text_with_newline)\n","\n","        # Extract the text for this section\n","        content = text_with_newline[start_pos:end_pos].strip()\n","\n","        # Create the chunk and add it to the list\n","        chunk = {\n","            'title': found_title,\n","            'content': content\n","        }\n","        chunks.append(chunk)\n","\n","    return chunks\n","\n","# usage\n","if __name__ == \"__main__\":\n","    pdf_path = \"/content/drive/MyDrive/ELAN_manual.pdf\"  # Replace with your PDF file path\n","    extracted_text = extract_text_from_pdf(pdf_path)\n","    titles = process_text(extracted_text)\n","    cleaned_text = cut_text_before_phrase(extracted_text, \"xxiChapter 1. ELAN documents\")\n","    chunks = divide_text_by_titles(cleaned_text, titles)\n","    chunks_cleaned = [el for el in chunks if el['title'] != el['content']]\n","    with open('/content/drive/MyDrive/ELAN_chunks.pkl', 'wb') as file:\n","      pickle.dump(chunks_cleaned, file)\n","\n","\n","\n"],"metadata":{"id":"huUf3exm2dRS"},"execution_count":null,"outputs":[]}]}